---
layout: single
title: "Daily Digest / 28 Feb 2023"
categories: papers
toc: true
toc_sticky: true
toc_label: Contents
---

### 1. Language Is Not All You Need: Aligning Perception with Language Models
- 이 모델은 텍스트와 이미지 같은 다양한 형태의 정보를 인식할 수 있으며, 컨텍스트에서 학습하여 지시사항을 따르는 등의 다양한 일을 할 수 있습니다.
- 이 모델은 웹 규모의 다중 모달 코퍼스를 사용하여 학습되는데요, 이 코퍼스에는 이미지와 텍스트가 마구 섞여 있어서, Kosmos-1은 이 둘을 적절하게 이해하고 연결하여 문제를 해결합니다.
- 언어 이해, 생성, OCR-free NLP(문서 이미지를 직접 입력받아 처리하는 기능) 및 다양한 인식-언어 작업 (예: 다중 모달 대화, 이미지 캡션 생성, 시각적 질문에 대한 대답)에서 탁월한 성능을 보여주며, 이러한 능력은 마치 인공지능의 궁극적인 목표인 '인간 수준의 지능'을 추구하는 것 같습니다.
- 더불어, Kosmos-1은 언어와 다중 모달 사이에서도 정보를 전달하고 이해하는 것이 가능하며, 이러한 능력을 활용하여 인공지능의 비언어적 추론 능력을 평가하는 Raven IQ 테스트 데이터셋도 만들었습니다.

### 2. SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks
- 이 논문은 인공지능 모델이 커질수록 필요한 컴퓨팅 자원이 늘어나는 문제를 해결하기 위해, Spiking Neural Networks (SNNs)라는 기술을 이용한 SpikeGPT 모델을 제안하고 있습니다.
- SNNs는 sparse하고 event-driven activations을 활용하여 딥러닝에서 발생하는 연산 비용을 줄일 수 있는 에너지 효율적인 방법인데요. 이 기술은 이미지 인식 분야에서 많은 경쟁력을 갖추고 있으나, 언어 생성 분야에서는 여전히 성능 문제가 있었습니다.
- 이 논문에서는 이러한 문제를 극복하고자 SpikeGPT라는 SNN 기반의 언어 생성 모델을 제안하였습니다.
- 제안된 모델은 binary, event-driven spiking activation units을 사용하여 구성되었으며, 45M, 125M, 260M 파라미터의 세 가지 모델을 제안하였습니다. 이는 현재까지의 backprop-trained SNN 모델보다 4배나 크다는 것입니다. 이 모델은 transformer block을 수정하여 multi-head self attention을 선형으로 변경하여 연산 복잡성을 줄이고, 일반적인 SNN과 마찬가지로 입력 토큰이 순차적으로 attention mechanism으로 전달되도록 설계되었습니다.
- 실험 결과, SpikeGPT 모델은 기존의 non-spiking 모델들과 경쟁력을 유지하면서도, neuromorphic hardware에서 5배 더 적은 에너지를 소비하는 것으로 나타났습니다. 이러한 성능은 Spiking Neural Networks 기술이 언어 생성 분야에서도 효과적으로 활용될 수 있음을 보여줍니다.
- SpikeGPT 모델의 코드 구현은 https://github.com/ridgerchu/SpikeGPT 에서 확인하실 수 있습니다.
- SNNs를 활용한 SpikeGPT 모델은 에너지 효율적이고 성능도 좋아, 점점 커지는 인공지능 모델을 돌리는 데 더욱 효과적일 것 같네요.

### 3. Internet Explorer: Targeted Representation Learning on the Open Web
- 이 논문에서는, 인공지능 모델이 대량의 이미지를 학습할 수 있도록, 기존의 방법과는 다른 새로운 접근 방식을 제안합니다.
- 이를 Internet Explorer라고 부르며, 이 모델은 웹 상에서 자동으로 적합한 이미지를 찾아내고, 이를 활용하여 원하는 작업을 수행할 수 있는 모델입니다.
- 기존의 방식은 큰 규모의 일반적인 모델을 미리 학습시켜 놓고, 이를 작은 데이터셋에서 fine-tuning 하는 것이었습니다. 그러나 이 방식은 이미지 데이터셋이 고정된 것이기 때문에, 매일 수십억개의 이미지가 업로드되는 웹 상에서 새로운 이미지들을 반영하기 어려웠습니다. 이에 대한 해결책으로, 이 논문에서는 Internet Explorer라는 새로운 방법을 제안합니다.
- Internet Explorer는 자가 지도 학습 방법을 활용하여 웹 상에서 관련 이미지를 찾아내어 학습하는 방식입니다. 이 모델은 웹 상에서 텍스트 쿼리를 통해 이미지를 찾은 후, 이를 다운로드하여 자가 지도 학습을 진행하고, 이를 바탕으로 더욱 적합한 이미지를 찾아내는 방식으로 동작합니다.
-  Internet Explorer를 다양한 데이터셋에서 평가해보았고, 단 한 대의 GPU 데스크톱으로 웹을 탐색하여 30-40시간 동안 학습을 진행해도 CLIP oracle 성능을 능가하거나 비슷한 성능을 보이는 것으로 나타났습니다. 이러한 성과는 인공지능 모델이 더욱 다양하고 많은 데이터를 학습할 수 있게 됨으로써, 더욱 발전할 수 있을 것으로 기대됩니다.
- Internet Explorer는 웹 상에서 자동으로 관련 이미지를 찾아내어 학습하는 모델입니다. 이 방법은 기존의 방식보다 더욱 다양하고 많은 데이터를 학습할 수 있으며, 이를 바탕으로 더욱 더 발전된 인공지능 모델을 만들 수 있게 될 것 같습니다.

### 4. ChatGPT: A Meta-Analysis after 2.5 Months
- 이 논문은 오픈AI에서 개발한 ChatGPT 출시 이후 2.5개월 동안의현재 인식 및 논의에 대해 조사한 결과를 종합적으로 분석한 논문입니다. 여기서는 300,000개 이상의 트윗과 150개 이상의 학술 논문을 분석하여 ChatGPT가 어떻게 인식되고 논의되는지 조사했습니다.
- 결과적으로, ChatGPT는 일반적으로 고품질로 평가되고, 소셜 미디어에서는 긍정적인 감정과 기쁨이 지배합니다. 하지만 출시 이후 인식이 약간 감소했으며, 기쁨이 감소하고 부정적인 놀람이 증가했습니다.또한, 영어 이외의 언어에서는 보다 부정적으로 인식됩니다. 최근 학술 논문에서는 ChatGPT가 의료 분야를 비롯한 다양한 분야에서 큰 기회로 인식되었지만, 윤리적인 문제로 인해 위협으로도 인식됩니다. 또한 교육 분야에서는 혼합적인 평가를 받고 있다고 합니다.

### 5. Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models
- 이 논문은 인공지능 언어 모델이 불확실성에 대한 표현을 인식하고 생성할 수 있는 능력에 대한 연구입니다.
- 여기서는 언어 모델의 불확실성에 대한 표현과 이를 생성할 수 있는 능력이 인간과 인공지능 간의 언어 사용에서 누락된 핵심 차원이라고 주장합니다. 날씨 예보나 의사의 진단과 같이 정보는 종종 검은색과 흰색이 아닌 회색 지대에 머물며, 불확실성의 표현은 인간 결정을 지원하기 위한 세세한 뉘앙스를 제공합니다. 인공지능 언어 모델이 실제 상황에서 점점 더 많이 사용되는 상황에서, 이러한 모델이 불확실성의 표현을 인식하고 생성할 수 있는지 여부와 모델이 자체적으로 불확실성을 표현하는 방법이 모델의 행동에 미치는 영향을 조사하였습니다.
- 이 논문에서는 불확실성의 표현을 프롬프트에 삽입하여 GPT3 모델이 생성하는 결과의 정확도를 조사하였고, 표현에 따라 80% 이상의 정확도 차이를 보였습니다. 이러한 표현의 언어 특성을 분석하였고, 자연스러운 확실성 표현이 있는 경우 정확도가 감소하는 것을 발견하였습니다. 또한, 모델이 자체적으로 불확실성을 표현하는 방법을 가르치면서, 모델이 확실성을 표현하도록 가르치면 모델 캘리브레이션이 약화된다는 결과를 얻었습니다.
- 이러한 결과는 인공지능 언어 모델이 신뢰성 높은 불확실성의 표현을 인식하고 생성하는 것이 어려운 것을 보여줍니다. 인공지능 언어 모델이 불확실성의 표현과 생성에 대한 능력을 개선하는 방향으로 연구가 필요한 것을 보여주네요.

### 6. Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback
- 이 논문에서는 대형 언어 모델(Large language model)들이 실제 문제 해결에 적용되기 위해서는 외부 지식(external knowledge)과 자동 피드백(automated feedback)이 필요하다는 것을 제안합니다.
- 이를 위해 LLM-Augmenter 시스템을 제안하며, 이 시스템은 LLM에 일련의 플러그인 모듈을 추가하여 외부 지식에 근거한 응답을 생성하도록 만듭니다. 또한 유틸리티 함수에 의해 생성된 피드백을 사용하여 LLM의 프롬프트를 반복적으로 개선합니다. 이러한 방법을 사용하여 업무 지향 대화 및 일반적인 질문 응답 문제를 해결하는 데 LLM-Augmenter가 효과적임을 실험적으로 검증하였습니다. 
- 이 시스템은 플루언시와 정보성을 유지하면서 ChatGPT의 환각(hallucination)을 크게 줄일 수 있습니다.
- 이 논문에서 제안한 LLM-Augmenter 시스템은 오픈소스로 공개되어 있습니다.

### 7. Theory of Mind May Have Spontaneously Emerged in Large Language Models
- 이 논문에서는 모델들이 인간과 같은 사회적 상호작용과 의사소통, 공감, 자의식 및 도덕성 등에 필수적인 인식론(ToM) 능력을 갖출 수 있는지를 조사했습니다.
- 사전 학습이나 예시 없이 기존 언어 모델들에게 인식론 테스트를 진행한 결과, 2022년 1월 버전의 GPT-3(davinci-002)는 7살 아동과 유사한 성능으로 70%의 테스트를 통과했고, 2022년 11월 버전의 GPT-3(davinci-003)은 9살 아동과 유사한 성능으로 93%의 테스트를 통과했습니다. 이러한 결과는 언어 모델들의 언어 능력이 향상되면서 인식론과 같은 인간의 독특한 능력이 컴퓨터 모델에서 자연스럽게 발생할 수 있다는 가능성을 보여주네요.
