---
layout: single
title: "Visual ChatGPT (2023-03-11)"
categories: [paper]
tag: [Language Models, Visual Foundation Models, Multi-modal, Image Processing, AI Collaboration]
toc: true
toc_sticky: true
toc_label: Contents
---

# Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models
[arxiv](https://arxiv.org/pdf/2303.04671.pdf), [github](https://github.com/microsoft/visual-chatgpt), [huggingface](https://huggingface.co/spaces/microsoft/visual_chatgpt)
- This paper introduces Visual ChatGPT, a system that enables users to interact with ChatGPT using both language and images.
- Visual ChatGPT incorporates different Visual Foundation Models to provide complex visual questions or editing instructions, requiring the collaboration of multiple AI models with multi-steps.
- The system allows for feedback and corrected results, and experiments show its effectiveness in investigating the visual roles of ChatGPT with the help of Visual Foundation Models.
- The paper highlights the potential of multi-modal AI collaboration and is accompanied by a publicly available implementation.

> We appreciate the open source of the following projects:
>   Hugging Face / LangChain / Stable Diffusion / ControlNet / InstructPix2Pix / CLIPSeg / BLIP

